<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>ANN and Deep Architectures</title>
    <link rel="stylesheet" type="text/css" href="ann.css">
</head>
<body>
    <div id='main'>
        <div id='first'>
            <div id="text">
                <h1>DD2437 Artificial Neural Networks and Deep Architectures</h1>   
                <h3>7.5 ECTS</h3>
            </div>   
            <div class='work'>
                <div class='item'>
                    <div id="text">
                        <p1>Course content: </p1></br></br>
                    
                    
                        <p1>
                            The course is concerned with computational problems in massively parallel artificial neural network (ANN) architectures, which rely on distributed simple computational nodes and robust learning algorithms that iteratively adjust the connections between the nodes heavily using the available data samples. The learning rule and network architecture determine specific computational properties of the ANN. The course offers an opportunity to develop the conceptual and theoretical understanding of computational capabilities of ANNs starting from simpler systems and progressively studying more advanced architectures, and hence exploring the breadth of learning types â€“ from strictly supervised to purely explorative unsupervised mode. The course content therefore includes among others multi-layer perceptrons (MLPs), self-organising maps (SOMs), Boltzmann machines, Hopfield networks and state-of-the-art deep neural networks (DNNs) along with the corresponding learning algorithms. An important objective of the course is for the students to gain practical experience of selecting, developing, applying and validating suitable networks and algorithms to effectively address a broad class of regression, classification, temporal prediction, data modelling, explorative data analytics or clustering problems. Finally, the course provides revealing insights into the principles of generalisation capabilities of ANNs, which underlie their predictive power.

                        </br></br>
                    
                        I took the course in autumn 2020. All practical work of the course was programmed in Python
                        </p1>
                        <br/><br/><br/>
                        <p1><a href="https://www.kth.se/student/kurser/kurs/DD2437?l=en">Link to KTH course directory</a></p1></br>
                        <p1><a href="https://gits-15.sys.kth.se/dwass/DD2437_44">Github repository</a></p1>
                    </div>
                </div>
            </div>
        </div>
        <div id='second'>
            <div class='work'>
                <div class='item-link'>
                    <a href="ann_A1.html">
                    <div id='a1'>
                        <p>Lab 1: MLPs and backpropagation</p>
                    </div>
                    </a>
                    <a href="ann_A2.html">
                    <div id='a2'>
                        <p>Lab 2: RBFs, competitive learning and self-organisation</p>
                    </div>
                    </a>
                    <a href="ann_A3.html">
                    <div id='a3'>
                        <p>Lab 3: Hopfield networks</p>
                    </div>
                    </a>
                    <a href="ann_A4.html">
                    <div id='a4'>
                        <p>Lab 4: Deep belief nets</p>
                    </div>
                    </a>
                </div>
                
            </div>
        </div> 
    </div>
</body>
</html>